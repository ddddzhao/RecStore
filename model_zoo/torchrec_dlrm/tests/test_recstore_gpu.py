import torch
import os
import sys
import unittest
import tempfile
import shutil
import argparse
from torchrec.sparse.jagged_tensor import KeyedJaggedTensor
from torchrec.sparse.jagged_tensor import KeyedTensor
from torchrec import EmbeddingBagCollection
from torchrec.modules.embedding_configs import EmbeddingBagConfig

RECSTORE_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../src'))
if RECSTORE_PATH not in sys.path:
    sys.path.insert(0, RECSTORE_PATH)

from python.pytorch.torchrec.EmbeddingBag import RecStoreEmbeddingBagCollection


def get_embedding_collection_class(use_torchrec=False):
    """æ ¹æ®å‚æ•°è¿”å›å¯¹åº”çš„EmbeddingBagCollectionç±»"""
    if use_torchrec:
        return TorchRecEmbeddingBagCollection
    else:
        return RecStoreEmbeddingBagCollection


class TorchRecEmbeddingBagCollection(EmbeddingBagCollection):
    """TorchRecå®˜æ–¹EmbeddingBagCollectionçš„åŒ…è£…ç±»ï¼Œä½¿å…¶æ¥å£ä¸RecStoreç‰ˆæœ¬ä¸€è‡´"""
    
    def __init__(self, embedding_bag_configs):
        # è½¬æ¢é…ç½®æ ¼å¼
        configs = [
            EmbeddingBagConfig(
                name=c["name"],
                embedding_dim=c["embedding_dim"],
                num_embeddings=c["num_embeddings"],
                feature_names=c.get("feature_names", [c["name"]])
            )
            for c in embedding_bag_configs
        ]
        super().__init__(tables=configs)
        
        # å­˜å‚¨é…ç½®
        self._embedding_bag_configs = configs
        
        # æ·»åŠ ä¸RecStoreç‰ˆæœ¬ä¸€è‡´çš„å±æ€§
        self.feature_keys = []
        self._embedding_dims = {}
        for config in configs:
            for feature_name in config.feature_names:
                self.feature_keys.append(feature_name)
                self._embedding_dims[feature_name] = config.embedding_dim
    
    def embedding_bag_configs(self):
        """è¿”å›é…ç½®åˆ—è¡¨ï¼Œä¸RecStoreç‰ˆæœ¬ä¿æŒä¸€è‡´"""
        return self._embedding_bag_configs
    
    def to(self, device):
        """é‡å†™toæ–¹æ³•ï¼Œç¡®ä¿æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡"""
        super().to(device)
        return self


class TestRecStoreEmbeddingBagCollectionGPU(unittest.TestCase):
    """æµ‹è¯•RecStoreEmbeddingBagCollectionåœ¨GPUä¸Šçš„å„ç§åŠŸèƒ½"""
    
    @classmethod
    def setUpClass(cls):
        """ç±»çº§åˆ«çš„è®¾ç½®ï¼Œæ£€æŸ¥CUDAå¯ç”¨æ€§"""
        if not torch.cuda.is_available():
            raise unittest.SkipTest("CUDAä¸å¯ç”¨ï¼Œè·³è¿‡GPUæµ‹è¯•")
        
        cls.device = torch.device('cuda:0')
        print(f"ä½¿ç”¨GPUè®¾å¤‡: {cls.device}")
        print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        print(f"å½“å‰GPU: {torch.cuda.get_device_name(0)}")
        
        # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºDEBUGä»¥è·å–æ›´å¤šä¿¡æ¯
        os.environ['RECSTORE_LOG_LEVEL'] = '3'
    
    def setUp(self):
        """æ¯ä¸ªæµ‹è¯•å‰çš„è®¾ç½®"""
        # ç¡®ä¿åœ¨GPUä¸Šè¿è¡Œ
        torch.cuda.empty_cache()
        
        # è·å–å‘½ä»¤è¡Œå‚æ•°ï¼Œå†³å®šä½¿ç”¨å“ªä¸ªå®ç°
        parser = argparse.ArgumentParser()
        parser.add_argument('--use-torchrec', action='store_true', 
                          help='ä½¿ç”¨TorchRecå®˜æ–¹EmbeddingBagCollectionè€Œä¸æ˜¯RecStoreç‰ˆæœ¬')
        args, _ = parser.parse_known_args()
        
        # æ ¹æ®å‚æ•°é€‰æ‹©å®ç°
        self.embedding_collection_class = get_embedding_collection_class(args.use_torchrec)
        self.use_torchrec = args.use_torchrec
        
        # åŸºç¡€é…ç½®
        self.basic_configs = [
            {
                "name": "test_table",
                "num_embeddings": 100,
                "embedding_dim": 16,
                "feature_names": ["test_feature"]
            }
        ]
        
        # å¤šè¡¨é…ç½®
        self.multi_table_configs = [
            {
                "name": "user_table",
                "num_embeddings": 1000,
                "embedding_dim": 16,
                "feature_names": ["user_id"]
            },
            {
                "name": "item_table", 
                "num_embeddings": 500,
                "embedding_dim": 16,
                "feature_names": ["item_id"]
            },
            {
                "name": "category_table",
                "num_embeddings": 100,
                "embedding_dim": 16,
                "feature_names": ["category_id"]
            }
        ]

    def test_gpu_initialization(self):
        """æµ‹è¯•GPUä¸Šçš„åˆå§‹åŒ–åŠŸèƒ½"""
        print(f"\n=== æµ‹è¯•GPUåˆå§‹åŒ– ({'TorchRec' if self.use_torchrec else 'RecStore'}) ===")
        ebc = self.embedding_collection_class(self.basic_configs)
        
        # éªŒè¯é…ç½®
        configs = ebc.embedding_bag_configs()
        self.assertEqual(len(configs), 1)
        self.assertEqual(configs[0].name, "test_table")
        self.assertEqual(configs[0].num_embeddings, 100)
        self.assertEqual(configs[0].embedding_dim, 16)
        
        # éªŒè¯ç‰¹å¾é”®
        self.assertEqual(ebc.feature_keys, ["test_feature"])
        
        print("âœ“ GPUåˆå§‹åŒ–æµ‹è¯•é€šè¿‡")

    def test_gpu_forward_pass(self):
        """æµ‹è¯•GPUä¸Šçš„å‰å‘ä¼ æ’­"""
        print(f"\n=== æµ‹è¯•GPUå‰å‘ä¼ æ’­ ({'TorchRec' if self.use_torchrec else 'RecStore'}) ===")
        ebc = self.embedding_collection_class(self.basic_configs)
        
        # å¯¹äºTorchRecç‰ˆæœ¬ï¼Œéœ€è¦å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU
        if self.use_torchrec:
            ebc = ebc.to(self.device)
        
        # æ„é€ GPUä¸Šçš„è¾“å…¥æ•°æ®
        kjt = KeyedJaggedTensor(
            keys=["test_feature"],
            values=torch.tensor([0, 1, 2], dtype=torch.int64, device=self.device),  # ä½¿ç”¨æœ‰æ•ˆçš„IDèŒƒå›´
            lengths=torch.tensor([2, 1], dtype=torch.int32, device=self.device)
        )
        
        # å‰å‘ä¼ æ’­
        result = ebc(kjt)
        
        # éªŒè¯ç»“æœ
        self.assertIsInstance(result, KeyedTensor)
        self.assertEqual(result.keys(), ["test_feature"])
        
        if self.use_torchrec:
            # TorchRecç‰ˆæœ¬ï¼šè¾“å‡ºå½¢çŠ¶æ˜¯(2, 16)ï¼Œlength_per_keyæ˜¯[16]
            self.assertEqual(result.values().shape, (2, 16))
            self.assertEqual(result.length_per_key(), [16])
        else:
            # RecStoreç‰ˆæœ¬ï¼šè¾“å‡ºå½¢çŠ¶æ˜¯(2, 16)ï¼Œlength_per_keyæ˜¯[2]
            self.assertEqual(result.values().shape, (2, 16))
            self.assertEqual(result.length_per_key(), [2])
        
        self.assertEqual(result.values().device, self.device)
        
        print(f"âœ“ GPUå‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡ï¼Œè¾“å‡ºå½¢çŠ¶: {result.values().shape}")

    def test_gpu_multi_table_forward_pass(self):
        """æµ‹è¯•GPUä¸Šå¤šè¡¨å‰å‘ä¼ æ’­"""
        print(f"\n=== æµ‹è¯•GPUå¤šè¡¨å‰å‘ä¼ æ’­ ({'TorchRec' if self.use_torchrec else 'RecStore'}) ===")
        ebc = self.embedding_collection_class(self.multi_table_configs)
        
        # å¯¹äºTorchRecç‰ˆæœ¬ï¼Œéœ€è¦å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU
        if self.use_torchrec:
            ebc = ebc.to(self.device)
        
        # æ„é€ GPUä¸Šçš„å¤šè¡¨è¾“å…¥æ•°æ®
        kjt = KeyedJaggedTensor(
            keys=["user_id", "item_id", "category_id"],
            values=torch.tensor([0, 1, 2, 3, 4], dtype=torch.int64, device=self.device),  # ä½¿ç”¨æœ‰æ•ˆçš„IDèŒƒå›´
            lengths=torch.tensor([1, 2, 2], dtype=torch.int32, device=self.device)
        )
        
        # å‰å‘ä¼ æ’­
        result = ebc(kjt)
        
        # éªŒè¯ç»“æœ
        self.assertIsInstance(result, KeyedTensor)
        self.assertEqual(result.keys(), ["user_id", "item_id", "category_id"])
        
        if self.use_torchrec:
            # TorchRecç‰ˆæœ¬ï¼šè¾“å‡ºå½¢çŠ¶æ˜¯(1, 48)ï¼Œlength_per_keyæ˜¯[16, 16, 16]
            self.assertEqual(result.values().shape, (1, 48))
            self.assertEqual(result.length_per_key(), [16, 16, 16])
        else:
            # RecStoreç‰ˆæœ¬ï¼šè¾“å‡ºå½¢çŠ¶æ˜¯(3, 16)ï¼Œlength_per_keyæ˜¯[1, 1, 1]
            self.assertEqual(result.values().shape, (3, 16))
            self.assertEqual(result.length_per_key(), [1, 1, 1])
        
        self.assertEqual(result.values().device, self.device)
        
        print(f"âœ“ GPUå¤šè¡¨å‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡ï¼Œè¾“å‡ºå½¢çŠ¶: {result.values().shape}")

    def test_gpu_gradient_update(self):
        """æµ‹è¯•GPUä¸Šçš„æ¢¯åº¦æ›´æ–°åŠŸèƒ½"""
        print(f"\n=== æµ‹è¯•GPUæ¢¯åº¦æ›´æ–°åŠŸèƒ½ ({'TorchRec' if self.use_torchrec else 'RecStore'}) ===")
        ebc = self.embedding_collection_class(self.basic_configs)
        
        # å¯¹äºTorchRecç‰ˆæœ¬ï¼Œéœ€è¦å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU
        if self.use_torchrec:
            ebc = ebc.to(self.device)
        
        # æ„é€ GPUä¸Šçš„è¾“å…¥æ•°æ®
        kjt = KeyedJaggedTensor(
            keys=["test_feature"],
            values=torch.tensor([0, 1, 2], dtype=torch.int64, device=self.device),  # ä½¿ç”¨æœ‰æ•ˆçš„IDèŒƒå›´
            lengths=torch.tensor([2, 1], dtype=torch.int32, device=self.device)
        )
        
        # å‰å‘ä¼ æ’­
        result = ebc(kjt)
        
        # æ„é€ GPUä¸Šçš„æ¢¯åº¦
        grad = torch.randn_like(result.values(), device=self.device)
        
        # åå‘ä¼ æ’­
        result.values().requires_grad_(True)
        result.values().backward(grad)
        
        print("âœ“ GPUæ¢¯åº¦æ›´æ–°æµ‹è¯•é€šè¿‡")

    def test_gpu_multi_table_gradient_update(self):
        """æµ‹è¯•GPUä¸Šå¤šè¡¨æ¢¯åº¦æ›´æ–°"""
        print(f"\n=== æµ‹è¯•GPUå¤šè¡¨æ¢¯åº¦æ›´æ–° ({'TorchRec' if self.use_torchrec else 'RecStore'}) ===")
        ebc = self.embedding_collection_class(self.multi_table_configs)
        
        # å¯¹äºTorchRecç‰ˆæœ¬ï¼Œéœ€è¦å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU
        if self.use_torchrec:
            ebc = ebc.to(self.device)
        
        # æ„é€ GPUä¸Šçš„å¤šè¡¨è¾“å…¥æ•°æ®
        kjt = KeyedJaggedTensor(
            keys=["user_id", "item_id", "category_id"],
            values=torch.tensor([0, 1, 2, 3, 4], dtype=torch.int64, device=self.device),  # ä½¿ç”¨æœ‰æ•ˆçš„IDèŒƒå›´
            lengths=torch.tensor([1, 2, 2], dtype=torch.int32, device=self.device)
        )
        
        # å‰å‘ä¼ æ’­
        result = ebc(kjt)
        
        # æ„é€ GPUä¸Šçš„æ¢¯åº¦
        grad = torch.randn_like(result.values(), device=self.device)
        
        # åå‘ä¼ æ’­
        result.values().requires_grad_(True)
        result.values().backward(grad)
        
        print("âœ“ GPUå¤šè¡¨æ¢¯åº¦æ›´æ–°æµ‹è¯•é€šè¿‡")

    def test_gpu_device_transfer(self):
        """æµ‹è¯•GPUè®¾å¤‡é—´æ•°æ®ä¼ è¾“"""
        print(f"\n=== æµ‹è¯•GPUè®¾å¤‡é—´æ•°æ®ä¼ è¾“ ({'TorchRec' if self.use_torchrec else 'RecStore'}) ===")
        ebc = self.embedding_collection_class(self.basic_configs)
        
        # å¯¹äºTorchRecç‰ˆæœ¬ï¼Œéœ€è¦å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU
        if self.use_torchrec:
            ebc = ebc.to(self.device)
        
        # åœ¨CPUä¸Šæ„é€ æ•°æ®
        cpu_kjt = KeyedJaggedTensor(
            keys=["test_feature"],
            values=torch.tensor([0, 1, 2], dtype=torch.int64),  # ä½¿ç”¨æœ‰æ•ˆçš„IDèŒƒå›´
            lengths=torch.tensor([2, 1], dtype=torch.int32)
        )
        
        # è½¬ç§»åˆ°GPU
        gpu_kjt = KeyedJaggedTensor(
            keys=cpu_kjt.keys(),
            values=cpu_kjt.values().to(self.device),
            lengths=cpu_kjt.lengths().to(self.device)
        )
        
        # åœ¨GPUä¸Šå‰å‘ä¼ æ’­
        result = ebc(gpu_kjt)
        
        # éªŒè¯ç»“æœåœ¨GPUä¸Š
        self.assertEqual(result.values().device, self.device)
        
        # è½¬ç§»å›CPU
        cpu_result = result.values().cpu()
        self.assertEqual(cpu_result.device.type, 'cpu')
        
        print("âœ“ GPUè®¾å¤‡é—´æ•°æ®ä¼ è¾“æµ‹è¯•é€šè¿‡")

    def test_gpu_large_batch_forward_pass(self):
        """æµ‹è¯•GPUä¸Šå¤§æ‰¹æ¬¡å‰å‘ä¼ æ’­"""
        print(f"\n=== æµ‹è¯•GPUå¤§æ‰¹æ¬¡å‰å‘ä¼ æ’­ ({'TorchRec' if self.use_torchrec else 'RecStore'}) ===")
        ebc = self.embedding_collection_class(self.basic_configs)
        
        # å¯¹äºTorchRecç‰ˆæœ¬ï¼Œéœ€è¦å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU
        if self.use_torchrec:
            ebc = ebc.to(self.device)
        
        # æ„é€ GPUä¸Šçš„å¤§æ‰¹æ¬¡æ•°æ®
        batch_size = 1000
        ids = torch.randint(0, 100, (batch_size,), dtype=torch.int64, device=self.device)  # ç¡®ä¿IDåœ¨0-99èŒƒå›´å†…
        lengths = torch.ones(batch_size, dtype=torch.int32, device=self.device)
        
        kjt = KeyedJaggedTensor(
            keys=["test_feature"],
            values=ids,
            lengths=lengths
        )
        
        # å‰å‘ä¼ æ’­
        result = ebc(kjt)
        
        # éªŒè¯ç»“æœ
        if self.use_torchrec:
            # TorchRecç‰ˆæœ¬ï¼šè¾“å‡ºå½¢çŠ¶æ˜¯(1000, 16)
            self.assertEqual(result.values().shape, (1000, 16))
        else:
            # RecStoreç‰ˆæœ¬ï¼šè¾“å‡ºå½¢çŠ¶æ˜¯(1000, 16)
            self.assertEqual(result.values().shape, (1000, 16))
        
        self.assertEqual(result.values().device, self.device)
        
        print("âœ“ GPUå¤§æ‰¹æ¬¡å‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡")

    def test_gpu_memory_management(self):
        """æµ‹è¯•GPUå†…å­˜ç®¡ç†"""
        print(f"\n=== æµ‹è¯•GPUå†…å­˜ç®¡ç† ({'TorchRec' if self.use_torchrec else 'RecStore'}) ===")
        ebc = self.embedding_collection_class(self.basic_configs)
        
        # å¯¹äºTorchRecç‰ˆæœ¬ï¼Œéœ€è¦å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU
        if self.use_torchrec:
            ebc = ebc.to(self.device)
        
        # è®°å½•åˆå§‹å†…å­˜ä½¿ç”¨
        initial_memory = torch.cuda.memory_allocated()
        
        # è¿›è¡Œå¤šæ¬¡å‰å‘ä¼ æ’­
        for i in range(10):
            kjt = KeyedJaggedTensor(
                keys=["test_feature"],
                values=torch.tensor([i % 100, (i+1) % 100, (i+2) % 100], dtype=torch.int64, device=self.device),  # ç¡®ä¿IDåœ¨æœ‰æ•ˆèŒƒå›´å†…
                lengths=torch.tensor([2, 1], dtype=torch.int32, device=self.device)
            )
            result = ebc(kjt)
            
            # ç¡®ä¿ç»“æœåœ¨GPUä¸Š
            self.assertEqual(result.values().device, self.device)
        
        # æ¸…ç†å†…å­˜
        torch.cuda.empty_cache()
        
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨æ˜¯å¦åˆç†
        final_memory = torch.cuda.memory_allocated()
        memory_increase = final_memory - initial_memory
        
        print(f"å†…å­˜ä½¿ç”¨å¢åŠ : {memory_increase / 1024 / 1024:.2f} MB")
        
        print("âœ“ GPUå†…å­˜ç®¡ç†æµ‹è¯•é€šè¿‡")

    def test_gpu_mixed_precision(self):
        """æµ‹è¯•GPUæ··åˆç²¾åº¦"""
        print(f"\n=== æµ‹è¯•GPUæ··åˆç²¾åº¦ ({'TorchRec' if self.use_torchrec else 'RecStore'}) ===")
        ebc = self.embedding_collection_class(self.basic_configs)
        
        # å¯¹äºTorchRecç‰ˆæœ¬ï¼Œéœ€è¦å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU
        if self.use_torchrec:
            ebc = ebc.to(self.device)
        
        # ä½¿ç”¨åŠç²¾åº¦
        with torch.amp.autocast('cuda'):
            kjt = KeyedJaggedTensor(
                keys=["test_feature"],
                values=torch.tensor([0, 1, 2], dtype=torch.int64, device=self.device),  # ä½¿ç”¨æœ‰æ•ˆçš„IDèŒƒå›´
                lengths=torch.tensor([2, 1], dtype=torch.int32, device=self.device)
            )
            
            result = ebc(kjt)
            
            # éªŒè¯ç»“æœ
            self.assertEqual(result.values().device, self.device)
            # æ³¨æ„ï¼šåœ¨æ··åˆç²¾åº¦ä¸‹ï¼Œè¾“å‡ºå¯èƒ½æ˜¯float16æˆ–float32
            self.assertIn(result.values().dtype, [torch.float16, torch.float32])
        
        print("âœ“ GPUæ··åˆç²¾åº¦æµ‹è¯•é€šè¿‡")

    def test_gpu_concurrent_operations(self):
        """æµ‹è¯•GPUå¹¶å‘æ“ä½œ"""
        print(f"\n=== æµ‹è¯•GPUå¹¶å‘æ“ä½œ ({'TorchRec' if self.use_torchrec else 'RecStore'}) ===")
        ebc = self.embedding_collection_class(self.basic_configs)
        
        # å¯¹äºTorchRecç‰ˆæœ¬ï¼Œéœ€è¦å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU
        if self.use_torchrec:
            ebc = ebc.to(self.device)
        
        # åˆ›å»ºå¤šä¸ªæµ
        streams = [torch.cuda.Stream() for _ in range(3)]
        
        results = []
        for i, stream in enumerate(streams):
            with torch.cuda.stream(stream):
                kjt = KeyedJaggedTensor(
                    keys=["test_feature"],
                    values=torch.tensor([i % 100, (i+1) % 100, (i+2) % 100], dtype=torch.int64, device=self.device),  # ç¡®ä¿IDåœ¨æœ‰æ•ˆèŒƒå›´å†…
                    lengths=torch.tensor([2, 1], dtype=torch.int32, device=self.device)
                )
                result = ebc(kjt)
                results.append(result)
        
        # åŒæ­¥æ‰€æœ‰æµ
        torch.cuda.synchronize()
        
        # éªŒè¯æ‰€æœ‰ç»“æœ
        for i, result in enumerate(results):
            self.assertEqual(result.values().device, self.device)
            if self.use_torchrec:
                self.assertEqual(result.values().shape, (2, 16))
            else:
                self.assertEqual(result.values().shape, (2, 16))
        
        print("âœ“ GPUå¹¶å‘æ“ä½œæµ‹è¯•é€šè¿‡")

    def test_gpu_error_handling(self):
        """æµ‹è¯•GPUé”™è¯¯å¤„ç†"""
        print(f"\n=== æµ‹è¯•GPUé”™è¯¯å¤„ç† ({'TorchRec' if self.use_torchrec else 'RecStore'}) ===")
        ebc = self.embedding_collection_class(self.basic_configs)
        
        # å¯¹äºTorchRecç‰ˆæœ¬ï¼Œéœ€è¦å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU
        if self.use_torchrec:
            ebc = ebc.to(self.device)
        
        if not self.use_torchrec:
            # æµ‹è¯•ä¸å­˜åœ¨çš„è¡¨ï¼ˆä»…RecStoreç‰ˆæœ¬æ”¯æŒï¼‰
            with self.assertRaises(RuntimeError):
                ebc.kv_client.pull("non_existent_table", torch.tensor([1], device=self.device))
        
        # æµ‹è¯•æ— æ•ˆçš„IDèŒƒå›´
        kjt = KeyedJaggedTensor(
            keys=["test_feature"],
            values=torch.tensor([999], dtype=torch.int64, device=self.device),  # è¶…å‡ºèŒƒå›´çš„ID
            lengths=torch.tensor([1], dtype=torch.int32, device=self.device)
        )
        
        if self.use_torchrec:
            # TorchRecç‰ˆæœ¬ä¼šæŠ›å‡ºRuntimeError
            with self.assertRaises(RuntimeError):
                result = ebc(kjt)
        else:
            # RecStoreç‰ˆæœ¬åº”è¯¥ä¸ä¼šæŠ›å‡ºå¼‚å¸¸ï¼Œè€Œæ˜¯è¿”å›é›¶å‘é‡
            result = ebc(kjt)
            self.assertEqual(result.values().shape, (1, 16))
            self.assertEqual(result.values().device, self.device)
        
        print("âœ“ GPUé”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")

    def test_gpu_performance_benchmark(self):
        """æµ‹è¯•GPUæ€§èƒ½åŸºå‡†"""
        print(f"\n=== æµ‹è¯•GPUæ€§èƒ½åŸºå‡† ({'TorchRec' if self.use_torchrec else 'RecStore'}) ===")
        ebc = self.embedding_collection_class(self.basic_configs)
        
        # å¯¹äºTorchRecç‰ˆæœ¬ï¼Œéœ€è¦å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU
        if self.use_torchrec:
            ebc = ebc.to(self.device)
        
        # é¢„çƒ­
        for _ in range(5):
            kjt = KeyedJaggedTensor(
                keys=["test_feature"],
                values=torch.tensor([0, 1, 2], dtype=torch.int64, device=self.device),  # ä½¿ç”¨æœ‰æ•ˆçš„IDèŒƒå›´
                lengths=torch.tensor([2, 1], dtype=torch.int32, device=self.device)
            )
            _ = ebc(kjt)
        
        torch.cuda.synchronize()
        
        # æ€§èƒ½æµ‹è¯•
        batch_size = 100
        num_iterations = 100
        
        start_event = torch.cuda.Event(enable_timing=True)
        end_event = torch.cuda.Event(enable_timing=True)
        
        start_event.record()
        
        for _ in range(num_iterations):
            kjt = KeyedJaggedTensor(
                keys=["test_feature"],
                values=torch.randint(0, 100, (batch_size,), dtype=torch.int64, device=self.device),  # ç¡®ä¿IDåœ¨0-99èŒƒå›´å†…
                lengths=torch.ones(batch_size, dtype=torch.int32, device=self.device)
            )
            result = ebc(kjt)
        
        end_event.record()
        torch.cuda.synchronize()
        
        elapsed_time = start_event.elapsed_time(end_event)
        throughput = num_iterations / (elapsed_time / 1000)  # iterations per second
        
        print(f"GPUæ€§èƒ½åŸºå‡†: {elapsed_time:.2f}ms for {num_iterations} iterations")
        print(f"ååé‡: {throughput:.2f} iterations/second")
        
        print("âœ“ GPUæ€§èƒ½åŸºå‡†æµ‹è¯•é€šè¿‡")

    def test_gpu_multi_device(self):
        """æµ‹è¯•å¤šGPUè®¾å¤‡"""
        print(f"\n=== æµ‹è¯•å¤šGPUè®¾å¤‡ ({'TorchRec' if self.use_torchrec else 'RecStore'}) ===")
        if torch.cuda.device_count() < 2:
            self.skipTest("éœ€è¦è‡³å°‘2ä¸ªGPUè®¾å¤‡")
        
        ebc = self.embedding_collection_class(self.basic_configs)
        
        # æµ‹è¯•åœ¨ä¸åŒGPUä¸Šè¿è¡Œ
        for device_id in range(min(2, torch.cuda.device_count())):
            device = torch.device(f'cuda:{device_id}')
            
            # å¯¹äºTorchRecç‰ˆæœ¬ï¼Œéœ€è¦å°†æ¨¡å‹ç§»åŠ¨åˆ°å½“å‰è®¾å¤‡
            if self.use_torchrec:
                ebc = ebc.to(device)
            
            with torch.cuda.device(device):
                kjt = KeyedJaggedTensor(
                    keys=["test_feature"],
                    values=torch.tensor([0, 1, 2], dtype=torch.int64, device=device),  # ä½¿ç”¨æœ‰æ•ˆçš„IDèŒƒå›´
                    lengths=torch.tensor([2, 1], dtype=torch.int32, device=device)
                )
                
                result = ebc(kjt)
                
                # éªŒè¯ç»“æœåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
                self.assertEqual(result.values().device, device)
        
        print("âœ“ å¤šGPUè®¾å¤‡æµ‹è¯•é€šè¿‡")

    def test_gpu_tensor_operations(self):
        """æµ‹è¯•GPUå¼ é‡æ“ä½œ"""
        print(f"\n=== æµ‹è¯•GPUå¼ é‡æ“ä½œ ({'TorchRec' if self.use_torchrec else 'RecStore'}) ===")
        ebc = self.embedding_collection_class(self.basic_configs)
        
        # å¯¹äºTorchRecç‰ˆæœ¬ï¼Œéœ€è¦å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU
        if self.use_torchrec:
            ebc = ebc.to(self.device)
        
        # æµ‹è¯•ä¸åŒçš„å¼ é‡æ“ä½œ
        kjt = KeyedJaggedTensor(
            keys=["test_feature"],
            values=torch.tensor([0, 1, 2], dtype=torch.int64, device=self.device),  # ä½¿ç”¨æœ‰æ•ˆçš„IDèŒƒå›´
            lengths=torch.tensor([2, 1], dtype=torch.int32, device=self.device)
        )
        
        result = ebc(kjt)
        
        # æµ‹è¯•å¼ é‡æ“ä½œ
        result_squared = result.values() ** 2
        result_sum = result.values().sum()
        result_mean = result.values().mean()
        
        # éªŒè¯æ“ä½œç»“æœ
        self.assertEqual(result_squared.device, self.device)
        self.assertEqual(result_sum.device, self.device)
        self.assertEqual(result_mean.device, self.device)
        
        print("âœ“ GPUå¼ é‡æ“ä½œæµ‹è¯•é€šè¿‡")

    def test_gpu_gradient_accumulation(self):
        """æµ‹è¯•GPUæ¢¯åº¦ç´¯ç§¯"""
        print(f"\n=== æµ‹è¯•GPUæ¢¯åº¦ç´¯ç§¯ ({'TorchRec' if self.use_torchrec else 'RecStore'}) ===")
        ebc = self.embedding_collection_class(self.basic_configs)
        
        # å¯¹äºTorchRecç‰ˆæœ¬ï¼Œéœ€è¦å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU
        if self.use_torchrec:
            ebc = ebc.to(self.device)
        
        # å¤šæ¬¡å‰å‘ä¼ æ’­å’Œæ¢¯åº¦ç´¯ç§¯
        accumulated_grad = None
        
        for i in range(3):
            kjt = KeyedJaggedTensor(
                keys=["test_feature"],
                values=torch.tensor([i % 100, (i+1) % 100, (i+2) % 100], dtype=torch.int64, device=self.device),  # ç¡®ä¿IDåœ¨æœ‰æ•ˆèŒƒå›´å†…
                lengths=torch.tensor([2, 1], dtype=torch.int32, device=self.device)
            )
            
            result = ebc(kjt)
            result.values().requires_grad_(True)
            
            # è®¡ç®—æŸå¤±
            loss = result.values().sum()
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # ç´¯ç§¯æ¢¯åº¦
            if accumulated_grad is None:
                accumulated_grad = result.values().grad.clone()
            else:
                accumulated_grad += result.values().grad
        
        # éªŒè¯æ¢¯åº¦ç´¯ç§¯
        self.assertIsNotNone(accumulated_grad)
        self.assertEqual(accumulated_grad.device, self.device)
        
        print("âœ“ GPUæ¢¯åº¦ç´¯ç§¯æµ‹è¯•é€šè¿‡")


def run_all_gpu_tests():
    """è¿è¡Œæ‰€æœ‰GPUæµ‹è¯•"""
    # è·å–å‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser()
    parser.add_argument('--use-torchrec', action='store_true', 
                      help='ä½¿ç”¨TorchRecå®˜æ–¹EmbeddingBagCollectionè€Œä¸æ˜¯RecStoreç‰ˆæœ¬')
    args, _ = parser.parse_known_args()
    
    implementation_name = "TorchRecå®˜æ–¹" if args.use_torchrec else "RecStore"
    print(f"å¼€å§‹è¿è¡Œ{implementation_name} EmbeddingBagCollection GPUæµ‹è¯•å¥—ä»¶...")
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨ï¼Œæ— æ³•è¿è¡ŒGPUæµ‹è¯•")
        return False
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestRecStoreEmbeddingBagCollectionGPU)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # æ‰“å°æ€»ç»“
    print(f"\nGPUæµ‹è¯•æ€»ç»“:")
    print(f"è¿è¡Œæµ‹è¯•æ•°: {result.testsRun}")
    print(f"å¤±è´¥æµ‹è¯•æ•°: {len(result.failures)}")
    print(f"é”™è¯¯æµ‹è¯•æ•°: {len(result.errors)}")
    print(f"è·³è¿‡æµ‹è¯•æ•°: {len(result.skipped)}")
    
    if result.failures:
        print("\nå¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"- {test}: {traceback}")
    
    if result.errors:
        print("\né”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"- {test}: {traceback}")
    
    if result.skipped:
        print("\nè·³è¿‡çš„æµ‹è¯•:")
        for test, reason in result.skipped:
            print(f"- {test}: {reason}")
    
    return result.wasSuccessful()


def main():
    """ä¸»å‡½æ•°ï¼Œè¿è¡Œæ‰€æœ‰GPUæµ‹è¯•"""
    success = run_all_gpu_tests()
    if success:
        print("\nğŸ‰ æ‰€æœ‰GPUæµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nâŒ éƒ¨åˆ†GPUæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯ã€‚")
    return success


if __name__ == "__main__":
    main()